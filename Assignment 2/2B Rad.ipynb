{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-3f286e56e14e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyworld_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyworld_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[0minertia\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minertia_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    969\u001b[0m                 \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy_x\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 971\u001b[1;33m                 return_n_iter=True)\n\u001b[0m\u001b[0;32m    972\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\k_means_.py\u001b[0m in \u001b[0;36mk_means\u001b[1;34m(X, n_clusters, sample_weight, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, algorithm, return_n_iter)\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[0morder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"C\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcopy_x\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     X = check_array(X, accept_sparse='csr', dtype=[np.float64, np.float32],\n\u001b[1;32m--> 311\u001b[1;33m                     order=order, copy=copy_x)\n\u001b[0m\u001b[0;32m    312\u001b[0m     \u001b[1;31m# verify that the number of samples given is larger than k\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 573\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# TASK 2B\n",
    "# Name: Radiance Tan\n",
    "# Student ID: 10961112\n",
    "##################################################################################################################\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import graphviz\n",
    "import sklearn\n",
    "import re\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import tree, neighbors\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import export_graphviz\n",
    "from itertools import groupby, combinations\n",
    "from sklearn.metrics import accuracy_score as ACS\n",
    "from sklearn.pipeline import make_pipeline as PIPE\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "from sklearn.model_selection import train_test_split as TTS\n",
    "\n",
    "\n",
    "'''----------- 'block_list' blocks country code into groups from A-Z and puts them into a dictionary -----------'''\n",
    "def block_list(mylist):\n",
    "    mydict={}\n",
    "    for k, g in itertools.groupby(mylist, lambda x: x[1][0]):\n",
    "        if k in mydict:\n",
    "            mydict[k] += g\n",
    "        else:\n",
    "            mydict[k]=list(g)\n",
    "    return mydict\n",
    "\n",
    "\n",
    "\n",
    "'''-------------------------- code below links the 2 csvs to produce a csv 'my_world' --------------------------'''\n",
    "life_df = pd.read_csv('life.csv', encoding = 'ISO-8859-1', usecols = ['Country', 'Country Code', 'Life expectancy at birth (years)'])\n",
    "world_df = pd.read_csv('world.csv', encoding = 'ISO-8859-1')\n",
    "world_df.dropna(subset=['Country Name'], inplace=True)\n",
    "world_df.drop(columns=['Time'], inplace=True)\n",
    "\n",
    "sort_life = sorted(life_df.values.tolist(), key=lambda x: x[1])\n",
    "sort_world = sorted(world_df.values.tolist(), key=lambda x: x[1])\n",
    "\n",
    "life_dict = block_list(sort_life)\n",
    "world_dict = block_list(sort_world)\n",
    "\n",
    "myworld = []\n",
    "life = ['Low', 'Medium', 'High']\n",
    "\n",
    "for k,v in world_dict.items():\n",
    "    match_val = life_dict.get(k)\n",
    "    \n",
    "    for row in v:\n",
    "        if not re.search(r\"[&(:]|dividend|income|euro|small|ida |ibrd|oecd|conflict|not |world\", (row[0]).lower()):\n",
    "            if match_val:\n",
    "                expectant_life = [z[2] for z in match_val if z[1]==row[1]]\n",
    "                if expectant_life != []:\n",
    "                    expectant_life = [life.index(expectant_life[0])]\n",
    "                    myworld.append(row[0:2] + expectant_life + row[2:])\n",
    "                elif expectant_life == [] and row.count('..') <= 14:\n",
    "                    myworld.append(row[0:2] + ['..'] + row[2:])\n",
    "        \n",
    "\n",
    "# feature names have been shortened for easy reference in the code\n",
    "features = ['[EG.ELC.ACCS.RU.ZS]', '[NY.ADJ.DPEM.GN.ZS]', '[SP.DYN.CBRT.IN]', '[SH.DTH.COMM.ZS]', '[SH.DTH.NCOM.ZS]', \n",
    "            '[SH.XPD.GHED.PC.CD]', '[IT.NET.USER.ZS]', '[SH.MMR.RISK.ZS]', '[SH.MMR.RISK]', '[SH.STA.MMRT]', '[SH.DYN.NCOM.FE.ZS]', \n",
    "            '[SH.STA.AIRP.P5]', '[SH.STA.AIRP.FE.P5]', '[SH.STA.AIRP.MA.P5]', '[SH.STA.POIS.P5.FE]', '[SH.STA.WASH.P5]', '[SH.H2O.BASW.ZS]', \n",
    "            '[SH.STA.BASS.ZS]', '[SH.STA.BASS.UR.ZS]', '[SH.ANM.CHLD.ZS]']\n",
    "\n",
    "\n",
    "col = ['CountryName', 'CountryCode', 'LifeExpectancy']+features\n",
    "myworld_df = pd.DataFrame(myworld, columns=col)\n",
    "myworld_df = myworld_df.replace('..', np.nan)\n",
    "myworld_df = myworld_df.fillna(myworld_df.median())\n",
    "myworld_df[features] = myworld_df[features].astype('float')\n",
    "\n",
    "\n",
    "new_combi = []\n",
    "combination = list(combinations(features, 2))\n",
    "for combi in combination:\n",
    "    name1 = (re.search(r\"\\[\\S+\\]\", combi[0])).group()\n",
    "    name2 = (re.search(r\"\\[\\S+\\]\", combi [1])).group()\n",
    "    myworld_df[name1+' x '+name2] = myworld_df[combi[0]] * myworld_df[combi[1]]\n",
    "    new_combi.append(name1+' x '+name2)\n",
    "\n",
    "\n",
    "'''------------------- finding optimal k for n_clusters and features for feature engineering -------------------'''\n",
    "new_features = myworld_df[features+new_combi]\n",
    "cluster_no = {} \n",
    "inertia = []\n",
    "\n",
    "for k in range(1,15): \n",
    "    model = KMeans(n_clusters=k).fit(myworld_df[features]) \n",
    "    model.fit(myworld_df[features])     \n",
    "    inertia.append(model.inertia_) \n",
    "    cluster_no[k] = model.inertia_ \n",
    "\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(range(1,15), inertia, 'bx-') \n",
    "plt.xlabel('Number of clusters') \n",
    "plt.ylabel('Inertia')\n",
    "plt.savefig('task2b_cluster_number.png')\n",
    "\n",
    "\n",
    "\n",
    "# replicating decision tree in task 2A. an error might occur here if graphviz is not installed to view the image\n",
    "data = myworld_df[features]\n",
    "X_train, X_test, y_train, y_test = TTS(data, myworld_df['LifeExpectancy'], train_size=0.66, test_size=0.34, random_state=100)\n",
    "\n",
    "scaler = SS().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "dt = DTC(random_state=100, max_depth=5)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred=dt.predict(X_test)\n",
    "\n",
    "tree.export_graphviz(dt,out_file=\"tree.dot\",feature_names=data.columns, filled=True)\n",
    "#! dot -Tpng tree.dot -o task2b_feature_selection.png\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''------------------------------- creating cluster labels and feature engineering -------------------------------'''\n",
    "kmeans = KMeans(n_clusters=4, random_state=100)\n",
    "kmeans.fit(myworld_df[features])\n",
    "myworld_df['clusterlabel'] = kmeans.predict(myworld_df[features])\n",
    "\n",
    "\n",
    "classlabel = myworld_df['LifeExpectancy']\n",
    "data1 = myworld_df[['clusterlabel', '[SH.MMR.RISK]', '[SH.STA.WASH.P5]', '[SH.DYN.NCOM.FE.ZS]']]\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = TTS(data1, classlabel, train_size=0.66, test_size=0.34, random_state=100)\n",
    "scaler1 = SS().fit(X_train1)\n",
    "X_train1 = scaler1.transform(X_train1)\n",
    "X_test1 = scaler1.transform(X_test1)\n",
    "\n",
    "knn1 = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn1.fit(X_train1, y_train1)\n",
    "y_pred1 = knn1.predict(X_test1)\n",
    "print(\"Accuracy of feature engineering: {:.3f}%\".format(ACS(y_test1, y_pred1)*100))\n",
    "\n",
    "\n",
    "'''---------------------------------------------------- PCA ----------------------------------------------------'''\n",
    "data = myworld_df.iloc[:, 3:]\n",
    "X_train2, X_test2, y_train2, y_test2 = TTS(data, classlabel, train_size=0.66, test_size=0.34, random_state=100)\n",
    "\n",
    "pca = PIPE(SS(), PCA(n_components=4, random_state=100))\n",
    "pca.fit(X_train2)\n",
    "X_train2 = pca.transform(X_train2)\n",
    "X_test2 = pca.transform(X_test2) \n",
    "\n",
    "knn2 = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn2.fit(X_train2, y_train2)\n",
    "y_pred2 = knn2.predict(X_test2)\n",
    "print(\"Accuracy of PCA: {:.3f}%\".format(ACS(y_test2, y_pred2)*100))\n",
    "\n",
    "\n",
    "'''--------------------------------------------- first 4 features ----------------------------------------------'''\n",
    "data3 = myworld_df[[\"[EG.ELC.ACCS.RU.ZS]\",\"[NY.ADJ.DPEM.GN.ZS]\", \"[SP.DYN.CBRT.IN]\",\"[SH.DTH.COMM.ZS]\"]]\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = TTS(data3, classlabel, train_size=0.66, test_size=0.34, random_state=100)\n",
    "scaler3 = SS().fit(X_train3)\n",
    "X_train3 = scaler3.transform(X_train3)\n",
    "X_test3 = scaler3.transform(X_test3)\n",
    "\n",
    "knn3 = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "knn3.fit(X_train3, y_train3)\n",
    "y_pred3 = knn3.predict(X_test3)\n",
    "print(\"Accuracy of first four features: {:.3f}%\".format(ACS(y_test3, y_pred3)*100))\n",
    "\n",
    "\n",
    "# used to check accuracies of train set\n",
    "# print(\"Accuracy of feature engineering (train set): {:.1f}%\".format(ACS(y_train1, knn1.predict(X_train1))*100))\n",
    "# print(\"Accuracy of PCA (train set): {:.1f}%\".format(ACS(y_train2, knn2.predict(X_train2))*100))\n",
    "# print(\"Accuracy of first 4 features (train set): {:.1f}%\".format(ACS(y_train3, knn3.predict(X_train3))*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
